# -*- coding: utf-8 -*-
"""Python for Statistical Analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1h3nEwdbMnjyl7uw6bZRe-mahyr9a7Vkg

#Introducion
"""

import matplotlib.pyplot as plt
import numpy as np

xs = np.linspace(0,9,100)
ys = np.sin(xs)

plt.plot(xs, ys, label="Cool Data")
plt.legend()

"""#Explore Data analysis

0. Manualy loading a file.
1. Using np.loadtext
2. Using np.genfromtxt
3. Using pd.read_csv
4. Using pickle
"""

import numpy as np
import pickle
import pandas as pd

filename = "load.csv"

cols = None
data = []
with open(filename) as f:
  for line in f.readlines():
    vals = line.replace("\n", "").split(",")
    if cols is None:
      cols = vals
    else:
      data.append([float(x) for x in vals])

d0 = pd.DataFrame(data, columns=cols)
print(d0.dtypes)
d0.head()

d1 = np.loadtxt(filename, skiprows=1, delimiter=",")
print(d1.dtype)
print(d1[:5, :])

d2 = np.genfromtxt(filename, delimiter=",", names=True, dtype=None)
print(d2.dtype)
print(d2[:5])

d3 = pd.read_csv(filename)
print(d3.dtypes)
d3.head()

with open("load_pickle.pickle", "rb") as f:
  d4 = pickle.load(f)
print(d4.dtypes)
d4.head()

"""#Dataset preparation - Diabetes"""

import pandas as pd
import numpy as np

df = pd.read_csv("Diabetes.csv")
df.info()

df.head()

df = df.fillna(0)

df2 = df[["Glucose", "BMI","Age","Outcome"]]

df2.head()

df2.describe()

df3 = df2.loc[~(df2[df2.columns[:-1]] == 0).any(axis=1)]
df3.describe()
df3.info()

df3.describe()

df3.groupby("Outcome").mean()

df3.groupby("Outcome").agg({"Glucose":"mean", "BMI":"median", "Age": "sum"})

df3.groupby("Outcome").agg({ "mean", "median"})

positive = df3.loc[df3["Outcome"] == 1]
negative = df3.loc[df3["Outcome"] == 0]

print(positive.shape, negative.shape)

df3.to_csv("clean_diabetes.csv", index=False)

"""#Manejo de Valores Atipicos"""

import numpy as np
import matplotlib.pyplot as plt

d1 = np.loadtxt("outlier_1d.txt")
d2 = np.loadtxt("outlier_2d.txt")
d3 = np.loadtxt("outlier_curve.txt")

print(d1.shape, d2.shape)

plt.scatter(d1, np.random.normal(7, 0.2, size=d1.size), s=1, alpha=0.5)
plt.scatter(d2[:,0],d2[:,1])
plt.show();
plt.plot(d3[:,0],d3[:,1]);

mean, std = np.mean(d1), np.std(d1)
z_score = np.abs((d1-mean)/std)
threshold = 3
good = z_score < threshold

print(f"Rejection{(~good).sum()} points")
from scipy.stats import norm
print(f"z-score of 3 corresponds to a prob of {100 * 2 * norm.sf(threshold):0.2f}%")
visual_scatter = np.random.normal(size=d1.size)
plt.scatter(d1[good], visual_scatter[good], s=2, label="Good", color="#4CAF50")
plt.scatter(d1[~good], visual_scatter[~good], s=2, label="Bad", color="#F44336")
plt.legend();

from scipy.stats import multivariate_normal as mn

mean, cov = np.mean(d2, axis=0), np.cov(d2.T)
good = mn(mean, cov).pdf(d2) > 0.01 / 100

plt.scatter(d2[good, 0], d2[good, 1], s=2, label="Good", color="#4CAF50")
plt.scatter(d2[~good, 0], d2[~good, 1], s=2, label="Bad", color="#F44336")
plt.legend()

xs, ys = d3.T
p = np.polyfit(xs, ys, deg=5)
ps= np.polyval(p, xs)
plt.plot(xs, ys, '.', label="Data")
plt.plot(xs, ps, label="Bad poly fit")
plt.legend();

x, y = xs.copy(), ys.copy()

for i in range(5):
  p = np.polyfit(x,y,deg=5)
  ps = np.polyval(p,x)

  good = y - ps < 3

  x_bad, y_bad = x[~good], y[~good]
  x, y = x[good], y[good]

  plt.plot(x,y,".", label="Used Data")
  plt.plot(x, np.polyval(p, x), label=f"Poly fit {i}")
  plt.plot(x_bad, y_bad,".", label="Not used Data")
  plt.legend()
  plt.show()

  if(~good).sum() == 0:
    break